% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/test_g_gof.R
\name{ts_g_gof}
\alias{ts_g_gof}
\title{G (Likelihood Ratio) Test of Goodness-of-Fit}
\usage{
ts_g_gof(
  data,
  expCounts = NULL,
  cc = c("none", "yates", "pearson", "williams")
)
}
\arguments{
\item{data}{A vector with the data}

\item{expCounts}{Optional dataframe with the categories and expected counts}

\item{cc}{Optional continuity correction. Either "none" (default), "yates", "pearson", or "williams"}
}
\value{
Dataframe with:
\item{n}{the sample size}
\item{k}{the number of categories}
\item{statistic}{the chi-square statistic}
\item{df}{the degrees of freedom}
\item{pValue}{two-sided p-value}
\item{minExp}{the minimum expected count}
\item{propBelow5}{the proportion of expected counts below 5}
\item{testUsed}{a description of the test used}
}
\description{
A test that can be used with a single nominal variable, to test if the probabilities in all the categories
are equal (the null hypothesis). If the test has a p-value below a pre-defined threshold (usually 0.05) the
assumption they are all equal in the population will be rejected.

There are quite a few tests that can do this. Perhaps the most commonly used is the Pearson chi-square test,
but also an exact multinomial, Freeman-Tukey, Neyman, Mod-Log Likelihood and Cressie-Read test are possible.
}
\details{
The formula used (Wilks, 1938, p. 62):
\deqn{G=2\times\sum_{i=1}^{k}\left(F_{i}\times ln\left(\frac{F_{i}}{E_{i}}\right)\right)}
\deqn{df = k - 1}
\deqn{sig. = 1 - \chi^2\left(G,df\right)}

With:
\deqn{n = \sum_{i=1}^k F_i}
If no expected counts provided:
\deqn{E_i = \frac{n}{k}}
else:
\deqn{E_i = n\times\frac{E_{p_i}}{n_p}}
\deqn{n_p = \sum_{i=1}^k E_{p_i}}

\emph{Symbols used}:
\itemize{
\item \eqn{k} the number of categories
\item \eqn{F_i} the (absolute) frequency of category i
\item \eqn{E_i} the expected frequency of category i
\item \eqn{E_{p_i}} the provided expected frequency of category i
\item \eqn{n} the sample size, i.e. the sum of all frequencies
\item \eqn{n_p} the sum of all provided expected counts
\item \eqn{\chi^2\left(\dots\right)}	the chi-square cumulative density function
}

The term ‘Likelihood Ratio Goodness-of-Fit’ can for example be found in an article
from Quine and Robinson (1985), the term ‘Wilks’s likelihood ratio test’ can also be found
in Li and Babu (2019, p. 331), while the term G-test is found in Hoey (2012, p. 4)

The Yates continuity correction (cc="yates") is calculated using (Yates, 1934, p. 222):
\deqn{F_i^\ast  = \begin{cases} F_i - 0.5 & \text{ if } F_i > E_i \\ F_i + 0.5 & \text{ if } F_i < E_i \\ F_i & \text{ if } F_i = E_i \end{cases}}
\deqn{G_Y=2\times\sum_{i=1}^{k}\left(F_i^\ast\times ln\left(\frac{F_i^\ast}{E_{i}}\right)\right)}
Where if \eqn{F_i^\ast = 0} then \eqn{F_i^\ast\times ln\left(\frac{F_i^\ast}{E_{i}}\right) = 0}

The Pearson correction (cc="pearson") is calculated using (E.S. Pearson, 1947, p. 157):
\deqn{G_{P} = G\times\frac{n - 1}{n}}

The Williams correction (cc="williams") is calculated using (Williams, 1976, p. 36):
\deqn{G_{W} = \frac{G}{q}}
With:
\deqn{q = 1 + \frac{k^2 - 1}{6\times n\times df}}
The formula is also used by McDonald (2014, p. 87)
}
\section{Alternatives}{


The library \emph{DescTools} has a similar function \emph{GTest()}

The library \emph{RVAideMemoire} has a similar function \emph{G.test()}
}

\examples{
#Example 1: dataframe
dataFile = "https://peterstatistics.com/Packages/ExampleData/GSS2012a.csv"
df1 <- read.csv(dataFile, sep=",", na.strings=c("", "NA"))
ex1 = df1['mar1']
ts_g_gof(ex1)

#Example 2: dataframe with various settings
ex2 = df1['mar1']
eCounts = data.frame(c("MARRIED", "DIVORCED", "NEVER MARRIED", "SEPARATED"), c(5,5,5,5))
ts_g_gof(ex2, expCounts=eCounts, cc="yates")
ts_g_gof(ex2, expCounts=eCounts, cc="pearson")
ts_g_gof(ex2, expCounts=eCounts, cc="williams")

#Example 3: a list
ex3 = c("MARRIED", "DIVORCED", "MARRIED", "SEPARATED", "DIVORCED", "NEVER MARRIED", 
"DIVORCED", "DIVORCED", "NEVER MARRIED", "MARRIED", "MARRIED", "MARRIED", "SEPARATED", 
"DIVORCED", "NEVER MARRIED", "NEVER MARRIED", "DIVORCED", "DIVORCED", "MARRIED")

ts_g_gof(ex3)

}
\references{
Hoey, J. (2012). The two-way likelihood ratio (G) test and comparison to two-way chi squared test. 1–6. https://doi.org/10.48550/ARXIV.1206.4881

Li, B., & Babu, G. J. (2019). \emph{A graduate course on statistical inference}. Springer.

McDonald, J. H. (2014). \emph{Handbook of biological statistics} (3rd ed.). Sparky House Publishing.

Pearson, E. S. (1947). The choice of statistical tests illustrated on the Interpretation of data classed in a 2 × 2 table. \emph{Biometrika, 34}(1/2), 139–167. https://doi.org/10.2307/2332518

Quine, M. P., & Robinson, J. (1985). Efficiencies of chi-square and likelihood Ratio goodness-of-fit tests. \emph{The Annals of Statistics, 13}(2), 727–742. https://doi.org/10.1214/aos/1176349550

Wilks, S. S. (1938). The large-sample distribution of the likelihood ratio for testing composite hypotheses. \emph{The Annals of Mathematical Statistics, 9}(1), 60–62. https://doi.org/10.1214/aoms/1177732360

Williams, D. A. (1976). Improved likelihood ratio tests for complete contingency tables. \emph{Biometrika, 63}(1), 33–37. https://doi.org/10.2307/2335081

Yates, F. (1934). Contingency tables involving small numbers and the chi square test. \emph{Supplement to the Journal of the Royal Statistical Society, 1}(2), 217–235. https://doi.org/10.2307/2983604
}
\author{
P. Stikker. \href{https://PeterStatistics.com}{Companion Website}, \href{https://www.youtube.com/stikpet}{YouTube Channel}, \href{https://www.patreon.com/bePatron?u=19398076}{Patreon donations}
}
