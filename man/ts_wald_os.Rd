% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/test_wald_os.R
\name{ts_wald_os}
\alias{ts_wald_os}
\title{One-Sample Wald Test}
\usage{
ts_wald_os(data, codes = NULL, p0 = 0.5, cc = c("none", "yates"))
}
\arguments{
\item{data}{A vector with the data}

\item{codes}{Optional vector with the two codes to use}

\item{p0}{The hypothesized proportion for the first category (default is 0.5)}

\item{cc}{use of continuity correction (default is "none")}
}
\value{
Dataframe with:
\item{n}{the sample size}
\item{statistic}{the test value}
\item{pValue}{two-sided p-value}
\item{testUsed}{a description of the test used}
}
\description{
A one-sample score test could be used with binary data, to test if the two categories
have a significantly different proportion. It is an approximation of a binomial test,
by using a standard normal distribution. Since the binomial distribution is discrete
while the normal is continuous, a so-called continuity correction can (should?) be
applied.

The null hypothesis is usually that the proportions of the two categories in the
population are equal (i.e. 0.5 for each). If the p-value of the test is below the
pre-defined alpha level (usually 5\% = 0.05) the null hypothesis is rejected and
the two categories differ in proportion significantly.

The input for the function doesn't have to be a binary variable.
A nominal variable can also be used and the two categories to compare indicated.

A significance in general is the probability of a result as in the sample,
or more extreme, if the null hypothesis is true.

Some info on the different tests can be found in \href{https://youtu.be/jQ-nSPTGOgE}{video}.
}
\details{
This test differs from the one-sample score test in the calculation of the standard error.
For the ‘regular’ version this is based on the expected proportion,
while for the Wald version it is done with the observed proportion.

The formula used (Wald, 1943):
\deqn{z=\frac{x - \mu}{SE}}
With:
\deqn{\mu = n\times p_0}
\deqn{SE = \sqrt{x\times\left(1 - \frac{x}{n}\right)}}

\emph{Symbols used:}
\itemize{
\item \eqn{x} is the number of successes in the sample
\item \eqn{p_0} the expected proportion (i.e. the proportion according to the null hypothesis)
}

If the Yates continuity correction is used the formula changes to (Yates, 1934, p. 222):
\deqn{z_{Yates} = \frac{\left|x - \mu\right| - 0.5}{SE}}

The formula used in the calculation is the one from IBM (2021, p. 997).
IBM refers to Agresti, most likely Agresti (2013, p. 10), who in turn
refer to Wald (1943)
}
\examples{
#Example 1: Numeric list
ex1 = c(1, 1, 2, 1, 2, 1, 2, 1)
ts_wald_os(ex1)
ts_wald_os(ex1, p0=0.3)
ts_wald_os(ex1, p0=0.3, cc="yates")

#Example 2: dataframe
dataFile = "https://peterstatistics.com/Packages/ExampleData/GSS2012a.csv"
df1 <- read.csv(dataFile, sep=",", na.strings=c("", "NA"))
ts_wald_os(df1['sex'])
ts_wald_os(df1['mar1'], codes=c("DIVORCED", "NEVER MARRIED"))

}
\references{
Agresti, A. (2013). \emph{Categorical data analysis} (3rd ed.). Wiley.

IBM SPSS Statistics Algorithms. (2021). IBM.

Wald, A. (1943). Tests of statistical hypotheses concerning several parameters when the number of observations is large. \emph{Transactions of the American Mathematical Society, 54}(3), 426–482. https://doi.org/10.2307/1990256

Yates, F. (1934). Contingency tables involving small numbers and the chi square test. \emph{Supplement to the Journal of the Royal Statistical Society, 1}(2), 217–235. https://doi.org/10.2307/2983604
}
\author{
P. Stikker. \href{https://PeterStatistics.com}{Companion Website}, \href{https://www.youtube.com/stikpet}{YouTube Channel}, \href{https://www.patreon.com/bePatron?u=19398076}{Patreon donations}
}
